{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Find_Learning_rate.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-r_tI-3IhsP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Import the necessary libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "np.set_printoptions(suppress=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UuF0n9ZQFyH2",
        "colab_type": "text"
      },
      "source": [
        "## Load the cifar dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNeH_uKFIled",
        "colab_type": "code",
        "outputId": "b8d0f6b6-a75e-4dcb-dd68-bfa72fd1bbce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "#download data\n",
        "(x_train, y_train),(x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "#labels=['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']\n",
        "\n",
        "#labels 0,1,8,9 --->  Transport\n",
        "#labels 2,3,4,5,6,7 ----> Animals\n",
        "#For training data combine the 10 classes to two classes,0 for transport and 1 for animals\n",
        "y_train[np.where(np.isin(y_train,[0,1,8,9]))] = 0\n",
        "y_train[np.where(np.isin(y_train,[2,3,4,5,6,7]))] = 1\n",
        "\n",
        "#two classes labels\n",
        "labels = ['Transport','Animal']\n",
        "#df1=pd.DataFrame(y_train, columns=['X'])\n",
        "#df1.X.value_counts()\n",
        "\n",
        "#For test data combine the 10 classes to two classes,0 for transport and 1 for animals\n",
        "y_test[np.where(np.isin(y_test,[0,1,8,9]))] = 0\n",
        "y_test[np.where(np.isin(y_test,[2,3,4,5,6,7]))] = 1\n",
        "x_train.shape\n",
        "y_train.shape"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Ay7kpYuz4XL",
        "colab_type": "code",
        "outputId": "f80f3f44-4163-477f-a36e-2905897711e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Install the library for using tensorboard in the colab environment\n",
        "!pip install tensorboardcolab"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorboardcolab in /usr/local/lib/python3.6/dist-packages (0.0.22)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMQSEsBkz930",
        "colab_type": "code",
        "outputId": "108d6136-62bf-44fc-e0e0-a233aee518f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Load the library and create a writer that will output information for tensorboard\n",
        "import tensorboardcolab"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWQdg5Qpz-lC",
        "colab_type": "code",
        "outputId": "72f0f019-2fb1-4f99-9ed1-b0615ec80452",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "tbc = tensorboardcolab.TensorBoardColab()\n",
        "\n",
        "writer = tbc.get_writer()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wait for 8 seconds...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0720 20:53:26.412325 140582032541568 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tensorboardcolab/core.py:49: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "TensorBoard link:\n",
            "https://5b47d21d.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bk9Q8IcPGCbO",
        "colab_type": "text"
      },
      "source": [
        "## Normalize the inputs and reshape the labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ptMZDWdInrO",
        "colab_type": "code",
        "outputId": "802c4859-9d43-42df-9fc0-a6499499275c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#reshape training labels to one-hot coding\n",
        "y_input = tf.keras.utils.to_categorical(y_train[:40000])\n",
        "\n",
        "#normalise the training data\n",
        "x_input = (x_train[:40000]  / 255.0)\n",
        "\n",
        "#subset validatuon data and reshape validation labels to one-hot coding\n",
        "y_valid = tf.keras.utils.to_categorical(y_train[40000:])\n",
        "x_valid = (x_train[40000:] / 255.0)\n",
        "\n",
        "#reshape test data\n",
        "x_test_input = x_test / 255.0"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "40000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5_Q-j-nf1OV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#function to divide the data into batches for training\n",
        "data_index = 0\n",
        "def generate_batch(batch_size):\n",
        "    global data_index\n",
        "    batch = np.ndarray(shape=(batch_size, 32, 32, 3), dtype=np.float32)  #the same shapes as train data\n",
        "    labels = np.ndarray(shape=(batch_size,2), dtype=np.float32)\n",
        "    for i in range(batch_size):\n",
        "        batch[i] = x_input[data_index]\n",
        "        labels[i] = y_input[data_index]\n",
        "        data_index = (data_index + 1) % len(x_input)\n",
        "    return batch, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YuUztoudGPfP",
        "colab_type": "text"
      },
      "source": [
        "## Create the placeholders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5V3BRCWIp6k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = tf.placeholder(tf.float32, shape=[None, 32, 32, 3])\n",
        "y_ = tf.placeholder(tf.float32, shape=[None, 2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bp_HciV2GVLG",
        "colab_type": "text"
      },
      "source": [
        "## Now we'll build the convolutional layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-z90d3mTIsAO",
        "colab_type": "code",
        "outputId": "dc88acef-3afc-4ff7-a850-5d23c0b875a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "# input Layer\n",
        "conv_layer = tf.keras.layers.Conv2D(filters=16, kernel_size=(3,3),activation=tf.nn.relu)(x)\n",
        "\n",
        "#Flatten layer\n",
        "\n",
        "flat_layer = tf.keras.layers.Flatten()(conv_layer)\n",
        "\n",
        "#Fully connected layer\n",
        "dense = tf.keras.layers.Dense(units=512, activation=tf.nn.relu)(flat_layer)\n",
        "\n",
        "# output layer using softmax activation function\n",
        "y = tf.keras.layers.Dense(units=2,activation=tf.nn.softmax)(dense)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0720 20:53:27.377913 140582032541568 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7821RL9mGcJL",
        "colab_type": "text"
      },
      "source": [
        "## Create the loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwwXUY71I7PR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#crossentropy loss function\n",
        "cost = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WozuwZz8GgS8",
        "colab_type": "text"
      },
      "source": [
        "## Set up the training parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAvKjNfOI7lm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "start_lr = 1e-10\n",
        "global_step = tf.Variable(0,trainable=False)\n",
        "lr = tf.train.exponential_decay(start_lr, global_step=global_step,decay_steps=100, decay_rate=1.30)\n",
        "optimizer= tf.train.AdamOptimizer(lr) \n",
        "gd_train =optimizer.minimize(cost,global_step=global_step)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxdPkoeHJVIR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define an accuracy assessment operation\n",
        "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
        "# to calculate the accuracy\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiE-5V2XoBjt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Write out the graph to tensorboard\n",
        "sess = tf.Session()\n",
        "writer.add_graph(sess.graph)\n",
        "sess.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0L9UjMxEKk29",
        "colab_type": "code",
        "outputId": "ce7062a5-d7d5-4383-f4f5-574e0ef009aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#we'll look at training/validation accuracy and training/validation loss as it changes during training\n",
        "#TensorBoard summary for the validation accuracy\n",
        "val_acc = tf.summary.scalar(name='val_acc', tensor=accuracy)\n",
        "\n",
        "#TensorBoard summary for the train accuracy\n",
        "train_acc = tf.summary.scalar(name='train_acc', tensor=accuracy)\n",
        "\n",
        "#TensorBoard summary for the validation loss\n",
        "loss_val = tf.summary.scalar(name='loss_val', tensor=cost)\n",
        "\n",
        "#TensorBoard summary for the train loss\n",
        "loss_train = tf.summary.scalar(name='loss_train', tensor=cost)\n",
        "\n",
        "#TensorBoard summary for the learning rate\n",
        "learning_rate = tf.summary.scalar(name=\"learning_rate\",tensor=lr)\n",
        "tf.summary.scalar(\"current_step\", global_step)\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'current_step:0' shape=() dtype=string>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLEGv0krGk_i",
        "colab_type": "text"
      },
      "source": [
        "## Create a session and run the training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znLTkQ4mI903",
        "colab_type": "code",
        "outputId": "f4b18f9f-2076-451b-8753-a24e62a60a5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "#Number of epochs and batch size\n",
        "epochs=12000\n",
        "batch_size= 128\n",
        "\n",
        "#Global variables initializer\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "#Starting the Tensorflow session\n",
        "sess = tf.Session()\n",
        "\n",
        "#Initializing the Variables\n",
        "sess.run(init)\n",
        "\n",
        "#Iterating through all the epochs\n",
        "for i in range(epochs):\n",
        "  \n",
        "  #increment global step for exponential decau learning rate\n",
        "  global_step = tf.train.get_global_step()\n",
        "  \n",
        "  # generate data batches\n",
        "  batch_x, batch_y = generate_batch(batch_size)\n",
        "  \n",
        "  #Feeding data into optimizer and calculate the training loss function and training accuracy\n",
        "  _,train_loss, train_acc = sess.run([gd_train,loss_train,train_accuracy], feed_dict={x:batch_x, y_:batch_y})\n",
        "      \n",
        "  #Feeding data into optimizer and calculate the validation loss function and validation accuracy\n",
        "  val_acc,val_loss= sess.run([val_accuracy,loss_val], feed_dict = { x: x_valid, y_: y_valid})\n",
        "  \n",
        "  rt= sess.run(learning_rate)\n",
        "  \n",
        "  # write scalars to tensorbaord\n",
        "  writer.add_summary(train_acc,i)\n",
        "  writer.add_summary(val_acc,i)\n",
        "  writer.add_summary(val_loss,i)\n",
        "  writer.add_summary(train_loss,i)\n",
        "  writer.add_summary(rt,i)\n",
        "  #print(sess.run(optimizer._lr))\n",
        "  if i%1000 == 0:\n",
        "    print('Training Step:' + str(i) + '  valid_Loss = ' + str(sess.run(cost, {x: x_valid, y_: y_valid})) +  '  train_Loss = ' + str(sess.run(cost, {x: batch_x, y_: batch_y})))\n",
        "    "
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Step:0  valid_Loss = 0.7287667  train_Loss = 0.7294983\n",
            "Training Step:1000  valid_Loss = 0.7282753  train_Loss = 0.7635807\n",
            "Training Step:2000  valid_Loss = 0.720246  train_Loss = 0.7507807\n",
            "Training Step:3000  valid_Loss = 0.65772015  train_Loss = 0.67588913\n",
            "Training Step:4000  valid_Loss = 0.447682  train_Loss = 0.39805686\n",
            "Training Step:5000  valid_Loss = 0.26390812  train_Loss = 0.26648942\n",
            "Training Step:6000  valid_Loss = 0.24621046  train_Loss = 0.22421446\n",
            "Training Step:7000  valid_Loss = 0.3387335  train_Loss = 0.17603448\n",
            "Training Step:8000  valid_Loss = 0.67597747  train_Loss = 0.69491243\n",
            "Training Step:9000  valid_Loss = nan  train_Loss = nan\n",
            "Training Step:10000  valid_Loss = nan  train_Loss = nan\n",
            "Training Step:11000  valid_Loss = nan  train_Loss = nan\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hPDDdE_JCSV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "ae72e83c-bfb9-496e-e42f-ecc260e2e4f5"
      },
      "source": [
        "#Evaluate the model by calculating the test data accuracy and print it\n",
        "y_prob = sess.run(y, feed_dict={x: x_test_input})\n",
        "\n",
        "print(y_prob.shape)\n",
        "y_pred = np.argmax(y_prob,axis=-1)\n",
        "print('test accuracy: ', np.sum(y_pred==y_test[:,0])/len(y_test))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 2)\n",
            "test accuracy:  0.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G53kbgpKJV9-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sess.close()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}